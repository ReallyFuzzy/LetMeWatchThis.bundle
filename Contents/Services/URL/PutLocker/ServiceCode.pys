import re, urlparse, cgi, urllib, urllib2, cookielib, urlparse

from datetime import date

from BeautifulSoup import BeautifulSoup
from htmlentitydefs import name2codepoint as n2cp

import sys

USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_2) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22'

def NormalizeURL(url):

	#Log("*********** In PutLocker / Sockshare normalizeURL")

	# Deal with special providerInfo URL built up by plugin to return
	# info about this provider. For all other normal URLs, do nothing. 
	if ("providerinfo" in url):
	
		# Extract out domain.
		match = re.search("(putlocker|sockshare)", url.lower())
		if (match is None):
			return url
	
		try:
			show = Prefs["show_" + match.group(1)]
		except Exception, ex:
			show = False
			
		if (show):
			return url + "&visible=true"
		else:
			return url
			
	else:
		return url
		
def MetadataObjectForURL(url):
 
	#Log('In MetadataObjectForURL for PutLocker / Sockshare (' + url + ')')
	
	return VideoClipObject(
		title = 'PutLocker / Sockshare Redirect Page',
		summary = 'PutLocker / Sockshare Redirect Page',
		thumb = None,
	)

def MediaObjectsForURL(url):

	#Log('In MediaObjectsForURL for PutLocker / Sockshare (' + url + ')')
	
	return [
		MediaObject(
			parts = [PartObject(key=Callback(PlayVideo, url=url))],
		)
	]
	
  	return ret

@indirect	
def PlayVideo(url):

	putlocker_host = urlparse.urlparse(url).netloc
	
	cj = cookielib.CookieJar()
	opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
	
	# Request Provider page.
	try:
		#Log('Requesting ' + url)
		request = urllib2.Request(url)
		request.add_header('User-agent', USER_AGENT)
		response = opener.open(request)
	
		# Read in location and content of PutLocker page.	
		soup = BeautifulSoup(response.read())
	
		provider_url = response.geturl()
		#Log(provider_url)
		if (provider_url.endswith('?404')):
			return LogProviderError('Video no longer available (404 Returned)')
			
	except Exception, ex:
		return LogProviderError("Error whilst retrieving initial provider page (" + url + ")", ex)
		
	
	# Read in form info...
	try:
		params = {}
		params['hash'] = soup.find('input', {'name' : 'hash' })['value']
		params['confirm'] = "Continue as Free User"
		#Log(params)
	except Exception, ex:
		return LogProviderError("Error whilst retrieving information to go from intial page to next page", ex)

	
	# Submit form by re-requesting the same page.
	try:
		#Log('Requesting ' + url)
		request = urllib2.Request(url)
		request.add_header('User-agent', USER_AGENT)
		request.add_data(urllib.urlencode(params))
		response = opener.open(request)
		
		# Read in data from response.
		content = response.read()
		#Log(content)
	except Exception, ex:
		return LogProviderError("Error whilst retrieving second provider page (" + url + ")", ex)
		
	
	# Look for playlist URL.
	playlist_res = re.search("playlist: \'(.*?)\'", content)
	
	if (playlist_res is None):
		
		# Couldn't find playlist URL on page.
		# Usually, that activates the download link, so try that.
		soup = BeautifulSoup(content)
		download_link = soup.find('a','download_file_link')

		if download_link is None:
			# No playlist and no download link. Might as well give up.
			return LogProviderError('Playlist element not found on video page.')
		else:
			final_url =  "http://" + putlocker_host + decode_htmlentities(download_link['href'])
			
			# Get final, final URL.
			try:
				#Log('Requesting ' + final_url)
				request = urllib2.Request(final_url)
				request.add_header('User-agent', USER_AGENT)
				request.add_header('Accept-Encoding','gzip, deflate')
				
				# Use an URL opener which doesn't follow 302s as otherwise we'll start
				# to download the video.
				opener_nofollow = urllib2.build_opener(
					urllib2.HTTPCookieProcessor(cj),NoRedirectHandler()
				)
				response = opener_nofollow.open(request)
			
				final_url = response.headers['Location']
				
			except Exception, ex:
				return LogProviderError("Error whilst retrieving playlist page (http://" + final_url + ")", ex)
			
			
	else:
	
		# We've got a playlist. Get the page and final url.
		playlist = playlist_res.group(1)
		
		#Log(playlist)
		
		# Fetch playlist
		try:
			#Log('Requesting ' + "http://" + putlocker_host + playlist)
			request = urllib2.Request("http://" + putlocker_host + playlist)
			request.add_header('User-agent', USER_AGENT)
			response = opener.open(request)
		
			final = response.read()
			#Log(final)
			
		except Exception, ex:
			return LogProviderError("Error whilst retrieving playlist page (http://" + putlocker_host + playlist + ")", ex)

	
		final_url_res = re.search("<media:content url=\"(.*?)\"", final)
		
		if (final_url_res is None):
			return LogProviderError('Playlist did not containt valid video URL')

		final_url = decode_htmlentities(final_url_res.group(1))
	
	# Some content is hosted on a CDN which may issue a further 302 to another server.
	# Plex should be able to follow this automatically, but let's add a note here as
	# a reminder in case this ever breaks....

	
	# Bit of a messy problem here....
	#
	# * Plex Laika client adds in a blank referer which provider does not like one bit.
	#   So we need to override it. Because of problem 3 below, the only way to do this
	#   is via adding httpHeaders in the URL which libCurl then parses.
	# * Plex transcoding client does not add referer and doesn't understand extra http
	#   headers in URL. So, no need to do anything, but really don't want to change the
	#   URL or we'll end with an invalid url.
	# * Neither seem to support httpHeaders added to ObjectContainer.
	#
	# So, need to manually set correct headers in the right client dependent way. <sigh>
	# This will most likely break something at some point.
	if (
		Client.Platform == ClientPlatform.MacOSX or
		Client.Platform == ClientPlatform.Linux or 
		Client.Platform == ClientPlatform.Windows
	):
		# Plex will send blank refere if this isn't set which is reject by provider
		final_url = final_url + "|Referer=" + url
		
	Log(final_url)
	
	oc = ObjectContainer(
		objects = [
			VideoClipObject(
				items = [
					MediaObject(
						parts = [PartObject(key=final_url)]
					)
				]
			)
		]
	)

	# Might as well set a sensible user agent string.
	oc.user_agent = USER_AGENT
	
	return oc
	

# Utility methods.
def LogProviderError(msg="", ex=None):

	Log("************************** PROVIDER ERROR: " + msg)
	raise Exception(msg)
	return []

# Replace encoded HTML entities with matching real character.
def substitute_entity(match):
	ent = match.group(3)
	
	if match.group(1) == "#":
		if match.group(2) == '':
			return unichr(int(ent))
		elif match.group(2) == 'x':
			return unichr(int('0x'+ent, 16))
	else:
		cp = n2cp.get(ent)

		if cp:
			return unichr(cp)
		else:
			return match.group()
			
# Replace encoded HTML entities with matching real character.
def decode_htmlentities(string):
	entity_re = re.compile(r'&(#?)(x?)(\d{1,5}|\w{1,8});')
	return entity_re.subn(substitute_entity, string)[0]
	

# urlib2 handler which doesn't automatically follow 302, but which instead returns the new
# location.
class NoRedirectHandler(urllib2.HTTPRedirectHandler):

    def http_error_302(self, req, fp, code, msg, headers):
        infourl = urllib.addinfourl(fp, headers, req.get_full_url())
        infourl.status = code
        infourl.code = code
        return infourl